# MiniTweetGPT-A-small-GPT-like-model-for-tweets-
MiniTweetGPT â€“ A lightweight GPT-like language model trained on ChatGPT-related tweets using PyTorch and Transformers. It can generate tweet-style text and learn patterns from social media language.
ğŸ”¹ Features

âœ… Small-scale transformer-based model
âœ… Trained on a real-world Twitter dataset
âœ… Uses PyTorch & Hugging Face Transformers
âœ… Tokenization with BERT-based tokenizer
âœ… Fine-tunable for better results
ğŸ“¥ Setup Kaggle API for Dataset Download
1ï¸âƒ£ Get Your Kaggle API Key

    Go to Kaggle and log in.
    Click your profile picture â†’ "Account".
    Scroll to the API section and click "Create New API Token".
    A file named kaggle.json will be downloaded.

2ï¸âƒ£ Upload kaggle.json to Google Colab

from google.colab import files

# Upload kaggle.json
files.upload()

3ï¸âƒ£ Move API Key to Correct Location

import os
import shutil

# Create Kaggle directory
os.makedirs("/root/.kaggle", exist_ok=True)

# Move API key
shutil.move("kaggle.json", "/root/.kaggle/")
os.chmod("/root/.kaggle/kaggle.json", 600)

4ï¸âƒ£ Install Kaggle & Download Dataset

!pip install kaggle
!kaggle datasets download tariqsays/chatgpt-twitter-dataset --unzip -p /content/data

ğŸš€ Next Steps

ğŸ”¹ Train the model further for better tweet generation
ğŸ”¹ Fine-tune using pre-trained GPT models (e.g., GPT-2)
ğŸ”¹ Improve text coherence & creativity
